{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# IMPORTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "COLAB = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "if COLAB:\n",
        "    %load_ext tensorboard\n",
        "    !git clone https://github.com/abodinier/DCGAN-dose-prediction.git\n",
        "    !pip install transformers\n",
        "    !pip install torchmetrics\n",
        "    import sys\n",
        "    sys.path.append(\"./DCGAN-dose-prediction/\")\n",
        "    \n",
        "    from google.colab import drive\n",
        "\n",
        "    drive.mount('/content/gdrive')\n",
        "    STORAGE = Path(\"/content/gdrive/MyDrive/dose-prediction\")\n",
        "else:\n",
        "    STORAGE = Path(\"./\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1JlrLBNyCS2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "import json\n",
        "import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import OrderedDict\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchsummary import summary\n",
        "from torchmetrics import Accuracy\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "from utils import log_images\n",
        "from metrics import mean_absolute_error, peak_signal_to_noise_ratio, structural_similarity_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext autoreload"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CONSTANTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZrED3dyyoM3"
      },
      "outputs": [],
      "source": [
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "DATA_DIR = Path(\"./MVA-Dose-Prediction/\")\n",
        "Tensor = torch.cuda.FloatTensor if DEVICE == \"cuda\" else torch.FloatTensor"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not DATA_DIR.is_dir():\n",
        "    !git clone https://github.com/soniamartinot/MVA-Dose-Prediction.git"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "o9Kb0WBDyCS3"
      },
      "source": [
        "## Visualize data images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKEONUXPKzFM"
      },
      "outputs": [],
      "source": [
        "def plot_sample(sample_folder_path):\n",
        "    plt.figure(figsize=(15, 4))\n",
        "    plt.subplot(1, 4, 1)\n",
        "    plt.imshow(np.swapaxes(np.load(sample_folder_path/'ct.npy'), 0, 1),\n",
        "              cmap='gray', origin='lower')\n",
        "    plt.title(\"CT\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 4, 2)\n",
        "    plt.imshow(np.swapaxes(np.load(sample_folder_path/'possible_dose_mask.npy'), 0, 1),\n",
        "              cmap='gray', origin='lower')\n",
        "    plt.title(\"Possible dose mask\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 4, 3)\n",
        "    plt.imshow(np.swapaxes(np.load(sample_folder_path/'structure_masks.npy').sum(axis=0), 0, 1),\n",
        "              cmap='gray', origin='lower')\n",
        "    plt.title(\"Structure masks\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 4, 4)\n",
        "    plt.imshow(np.swapaxes(np.load(sample_folder_path/'dose.npy'), 0, 1),\n",
        "              cmap='gray', origin='lower')\n",
        "    plt.title(\"Dose\")\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 670
        },
        "id": "mTV0-ORtig-A",
        "outputId": "f72f977e-d271-4e20-a331-6b55ef690251"
      },
      "outputs": [],
      "source": [
        "all_train_samples = list((DATA_DIR/\"train\").iterdir())\n",
        "n_train_samples = len(all_train_samples)\n",
        "\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "for i in np.random.choice(np.arange(0, n_train_samples), 3):\n",
        "  path = all_train_samples[i]\n",
        "  plot_sample(path)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-d5qC_4ayCS4"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ZTzhiTgig-C"
      },
      "outputs": [],
      "source": [
        "class DoseDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, root, mode=\"train\"):\n",
        "\n",
        "        self.files = sorted((root/mode).iterdir())\n",
        "        self.mode = mode\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img = np.vstack(\n",
        "            (\n",
        "                np.load(self.files[index]/\"ct.npy\")[np.newaxis, :, :],\n",
        "                np.load(self.files[index]/\"structure_masks.npy\")\n",
        "            )\n",
        "        )\n",
        "        return {\n",
        "            \"ct\": np.load(self.files[index]/\"ct.npy\"),\n",
        "            \"structure_masks\": np.load(self.files[index]/\"structure_masks.npy\"),\n",
        "            \"img\": img, \n",
        "            \"possible_dose_mask\": np.load(self.files[index]/\"possible_dose_mask.npy\"),\n",
        "            \"dose\": np.load(self.files[index]/\"dose.npy\") if self.mode != \"test\" else None,\n",
        "        }\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JZi8M8vByCS4"
      },
      "source": [
        "# MODEL\n",
        "\n",
        "## Architecture:\n",
        "- Generator :\n",
        "  - UNet\n",
        "- Discrimintor :\n",
        "  - 3 layer-CNN with a 2-layer Dense classification head"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9s9mIiETyCS5"
      },
      "source": [
        "## Generator\n",
        "\n",
        "Convolutional UNet with 5 downscale layers and 5 upscale layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels=11, out_channels=1):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        feature_maps = 32\n",
        "        self.encoder1 = Generator._block(in_channels, feature_maps, name=\"enc1\")\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.encoder2 = Generator._block(feature_maps, feature_maps * 2, name=\"enc2\")\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.encoder3 = Generator._block(feature_maps * 2, feature_maps * 4, name=\"enc3\")\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.encoder4 = Generator._block(feature_maps * 4, feature_maps * 8, name=\"enc4\")\n",
        "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.bottleneck = Generator._block(feature_maps * 8, feature_maps * 16, name=\"bottleneck\")\n",
        "\n",
        "        self.upconv4 = nn.ConvTranspose2d(\n",
        "            feature_maps * 16, feature_maps * 8, kernel_size=2, stride=2\n",
        "        )\n",
        "        self.decoder4 = Generator._block((feature_maps * 8) * 2, feature_maps * 8, name=\"dec4\")\n",
        "        self.upconv3 = nn.ConvTranspose2d(\n",
        "            feature_maps * 8, feature_maps * 4, kernel_size=2, stride=2\n",
        "        )\n",
        "        self.decoder3 = Generator._block((feature_maps * 4) * 2, feature_maps * 4, name=\"dec3\")\n",
        "        self.upconv2 = nn.ConvTranspose2d(\n",
        "            feature_maps * 4, feature_maps * 2, kernel_size=2, stride=2\n",
        "        )\n",
        "        self.decoder2 = Generator._block((feature_maps * 2) * 2, feature_maps * 2, name=\"dec2\")\n",
        "        self.upconv1 = nn.ConvTranspose2d(\n",
        "            feature_maps * 2, feature_maps, kernel_size=2, stride=2\n",
        "        )\n",
        "        self.decoder1 = Generator._block(feature_maps * 2, feature_maps, name=\"dec1\")\n",
        "\n",
        "        self.conv = nn.Conv2d(\n",
        "            in_channels=feature_maps, out_channels=out_channels, kernel_size=1\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        enc1 = self.encoder1(x)\n",
        "        enc2 = self.encoder2(self.pool1(enc1))\n",
        "        enc3 = self.encoder3(self.pool2(enc2))\n",
        "        enc4 = self.encoder4(self.pool3(enc3))\n",
        "\n",
        "        bottleneck = self.bottleneck(self.pool4(enc4))\n",
        "\n",
        "        dec4 = self.upconv4(bottleneck)\n",
        "        dec4 = torch.cat((dec4, enc4), dim=1)\n",
        "        dec4 = self.decoder4(dec4)\n",
        "        dec3 = self.upconv3(dec4)\n",
        "        dec3 = torch.cat((dec3, enc3), dim=1)\n",
        "        dec3 = self.decoder3(dec3)\n",
        "        dec2 = self.upconv2(dec3)\n",
        "        dec2 = torch.cat((dec2, enc2), dim=1)\n",
        "        dec2 = self.decoder2(dec2)\n",
        "        dec1 = self.upconv1(dec2)\n",
        "        dec1 = torch.cat((dec1, enc1), dim=1)\n",
        "        dec1 = self.decoder1(dec1)\n",
        "        return self.conv(dec1)\n",
        "\n",
        "    @staticmethod\n",
        "    def _block(in_channels, feature_maps, name):\n",
        "        return nn.Sequential(\n",
        "            OrderedDict(\n",
        "                [\n",
        "                    (\n",
        "                        name + \"conv1\",\n",
        "                        nn.Conv2d(\n",
        "                            in_channels=in_channels,\n",
        "                            out_channels=feature_maps,\n",
        "                            kernel_size=3,\n",
        "                            padding=1,\n",
        "                            bias=False,\n",
        "                        ),\n",
        "                    ),\n",
        "                    (name + \"norm1\", nn.BatchNorm2d(num_features=feature_maps)),\n",
        "                    (name + \"relu1\", nn.ReLU(inplace=True)),\n",
        "                    (\n",
        "                        name + \"conv2\",\n",
        "                        nn.Conv2d(\n",
        "                            in_channels=feature_maps,\n",
        "                            out_channels=feature_maps,\n",
        "                            kernel_size=3,\n",
        "                            padding=1,\n",
        "                            bias=False,\n",
        "                        ),\n",
        "                    ),\n",
        "                    (name + \"norm2\", nn.BatchNorm2d(num_features=feature_maps)),\n",
        "                    (name + \"relu2\", nn.ReLU(inplace=True)),\n",
        "                ]\n",
        "            )\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEwEctDFig-E",
        "outputId": "69cfc118-b26c-4e39-d9cd-57f982817f8c"
      },
      "outputs": [],
      "source": [
        "summary(Generator().to(DEVICE), input_size=(11, 128, 128))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfoH5uweyCS5"
      },
      "source": [
        "## Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gdJB2mZgyCS6"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, dropout=0.1):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.model = torch.nn.Sequential(\n",
        "            torch.nn.LazyConv2d(128, 5),\n",
        "            torch.nn.MaxPool2d(2),\n",
        "            torch.nn.BatchNorm2d(128),\n",
        "            torch.nn.ReLU(),\n",
        "            \n",
        "            torch.nn.Conv2d(128, 256, 3),\n",
        "            torch.nn.MaxPool2d(2),\n",
        "            torch.nn.BatchNorm2d(256),\n",
        "            torch.nn.ReLU(),\n",
        "            \n",
        "            torch.nn.Conv2d(256, 256, 3),\n",
        "            torch.nn.MaxPool2d(2),\n",
        "            torch.nn.BatchNorm2d(256),\n",
        "            torch.nn.ReLU(),\n",
        "            \n",
        "            torch.nn.Flatten(),\n",
        "            torch.nn.Dropout(dropout),\n",
        "            torch.nn.LazyLinear(100),\n",
        "            torch.nn.Dropout(dropout),\n",
        "            torch.nn.Linear(100, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, labels):\n",
        "        # x: the ct inputs:  [bs, 11, 128, 128]\n",
        "        # labels: the dose mask:  [bs, 1, 128, 128]\n",
        "        x = torch.cat((x, labels), dim=1)  # [bs, 12, 128, 128]\n",
        "        return self.model(x)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Hyper parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ALPHA = 0.3  # ALPHA = 1 => only adversarial loss, ALPHA = 0 => only L1 loss\n",
        "\n",
        "LR_G = 1e-3\n",
        "LR_D = 1e-3\n",
        "\n",
        "N_EPOCHS = 50\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "train_dataset = DoseDataset(root=DATA_DIR, mode=\"train_small\")\n",
        "test_dataset = DoseDataset(root=DATA_DIR, mode=\"test\")\n",
        "val_dataset = DoseDataset(root=DATA_DIR, mode=\"validation_small\")\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "NUM_TRAINING_STEPS = N_EPOCHS * len(train_dataloader)\n",
        "\n",
        "hp = {\n",
        "    \"alpha\": ALPHA,\n",
        "    \"lr_g\": LR_G,\n",
        "    \"lr_d\": LR_D,\n",
        "    \"n_epochs\": N_EPOCHS,\n",
        "    \"batch_size\": BATCH_SIZE,\n",
        "    \"num_training_steps\": NUM_TRAINING_STEPS\n",
        "}\n",
        "\n",
        "\n",
        "EXP_NAME = \"CNN\"\n",
        "TIMESTAMP = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "EXP_DIR = STORAGE/\"trains\"/f\"{EXP_NAME}_{TIMESTAMP}\"\n",
        "EXP_DIR.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "with open(EXP_DIR/'hp.json', 'w') as f: json.dump(hp, f)\n",
        "\n",
        "logger = SummaryWriter(log_dir=EXP_DIR/\"logger\", comment=str(hp))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## GAN training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZyDg2hlyCS7",
        "outputId": "94a2bcad-c33c-4738-dda6-e8c8eef5683e"
      },
      "outputs": [],
      "source": [
        "l1_criterion = torch.nn.L1Loss().to(DEVICE)\n",
        "cross_entropy_loss = torch.nn.BCEWithLogitsLoss().to(DEVICE)\n",
        "accuracy_fn = Accuracy(task=\"binary\").to(DEVICE)\n",
        "\n",
        "# Initialize the generator\n",
        "generator = Generator().to(DEVICE)\n",
        "discriminator = Discriminator().to(DEVICE)\n",
        "\n",
        "# Optimizer\n",
        "optimizerG = torch.optim.Adam(\n",
        "    generator.parameters(),\n",
        "    lr=LR_G,\n",
        ")\n",
        "lr_scheduler_g = get_linear_schedule_with_warmup(optimizer=optimizerG, num_training_steps=2 * NUM_TRAINING_STEPS, num_warmup_steps=0.1 * NUM_TRAINING_STEPS)\n",
        "\n",
        "optimizerD = torch.optim.Adam(\n",
        "    discriminator.parameters(),\n",
        "    lr=LR_D,\n",
        ")\n",
        "lr_scheduler_d = get_linear_schedule_with_warmup(optimizer=optimizerD, num_training_steps=2 * NUM_TRAINING_STEPS, num_warmup_steps=0.1 * NUM_TRAINING_STEPS)\n",
        "\n",
        "prev_time = time.time()\n",
        "\n",
        "progress_bar = tqdm(total=NUM_TRAINING_STEPS)\n",
        "\n",
        "lr_values_d = []\n",
        "lr_values_g = []\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    train_l1_loss_g = []\n",
        "    train_adversarial_loss_g = []\n",
        "    val_l1_loss_g = []\n",
        "    val_adversarial_loss_g = []\n",
        "    \n",
        "    train_loss_d = []\n",
        "    val_loss_d = []\n",
        "    train_acc_d = []\n",
        "    val_acc_d = []\n",
        "\n",
        "    for i, batch in enumerate(train_dataloader):\n",
        "\n",
        "        img = batch[\"img\"].type(Tensor)\n",
        "        real_dose = batch[\"dose\"].type(Tensor)\n",
        "        \n",
        "        # Train Discriminator\n",
        "        optimizerD.zero_grad()\n",
        "        \n",
        "        discriminator_on_real_dose = discriminator(img, real_dose[:, None, :, :])\n",
        "        pos_sample_labels = torch.ones(size=(len(real_dose), 1), device=DEVICE)\n",
        "        pos_sample_preds = torch.nn.Sigmoid()(discriminator_on_real_dose)\n",
        "        \n",
        "        pos_samples_loss = cross_entropy_loss(\n",
        "            input=discriminator_on_real_dose, target=pos_sample_labels\n",
        "        )\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            generated_dose = generator(img)\n",
        "        discriminator_on_generated_dose = discriminator(img, generated_dose.detach())\n",
        "        neg_sample_labels = torch.zeros(size=(len(real_dose), 1), device=DEVICE)\n",
        "        neg_samples_loss = cross_entropy_loss(\n",
        "            input=discriminator_on_generated_dose, target=neg_sample_labels\n",
        "        )\n",
        "        neg_sample_preds = torch.nn.Sigmoid()(discriminator_on_generated_dose)\n",
        "        \n",
        "        discriminator_loss = (pos_samples_loss + neg_samples_loss) / 2\n",
        "        discriminator_loss.backward()\n",
        "        optimizerD.step()\n",
        "        lr_values_d.append(optimizerD.param_groups[0][\"lr\"])\n",
        "        lr_scheduler_d.step()\n",
        "        \n",
        "        train_loss_d.append(discriminator_loss.item())\n",
        "        \n",
        "        d_acc = accuracy_fn(\n",
        "            torch.cat((pos_sample_preds, neg_sample_preds), dim=-1),\n",
        "            torch.cat((pos_sample_labels, neg_sample_labels), dim=-1).type(torch.int)\n",
        "        ).item()\n",
        "        train_acc_d.append(d_acc)\n",
        "        \n",
        "        \n",
        "        # Train Generator\n",
        "        optimizerG.zero_grad()\n",
        "        generated_dose = generator(img)\n",
        "        generator_l1_loss = l1_criterion(\n",
        "            input=generated_dose[:, 0, :, :],\n",
        "            target=real_dose\n",
        "        )\n",
        "        discriminator_on_generated_dose = discriminator(img, generated_dose)\n",
        "        generator_adversarial_loss = cross_entropy_loss(\n",
        "            input=discriminator_on_generated_dose,\n",
        "            target=torch.ones(size=(len(real_dose), 1), device=DEVICE)\n",
        "        )\n",
        "        \n",
        "        generator_loss = ALPHA * generator_adversarial_loss + (1 - ALPHA) * generator_l1_loss\n",
        "        generator_loss.backward()\n",
        "        optimizerG.step()\n",
        "        lr_values_g.append(optimizerG.param_groups[0][\"lr\"])\n",
        "        lr_scheduler_g.step()\n",
        "        \n",
        "        train_l1_loss_g.append(generator_l1_loss.item())\n",
        "        train_adversarial_loss_g.append(generator_adversarial_loss.item())\n",
        "    \n",
        "        progress_bar.update(1)\n",
        "    \n",
        "    logger.add_scalar(tag=f\"train/discrimintor_loss\", scalar_value=np.mean(train_loss_d), global_step=epoch)\n",
        "    logger.add_scalar(tag=f\"train/discrimintor_accuracy\", scalar_value=np.mean(train_acc_d), global_step=epoch)\n",
        "    logger.add_scalar(tag=f\"train/generator_l1_loss\", scalar_value=np.mean(train_l1_loss_g), global_step=epoch)\n",
        "    logger.add_scalar(tag=f\"train/generator_adversarial_loss\", scalar_value=np.mean(train_adversarial_loss_g), global_step=epoch)\n",
        "\n",
        "    for batch in DataLoader(train_dataset, batch_size=5, shuffle=True):\n",
        "        fig = log_images(batch, generator, discriminator, Tensor)\n",
        "        logger.add_figure(tag=f\"train/image\", figure=fig, global_step=epoch)\n",
        "        break\n",
        "    \n",
        "    \n",
        "    for i, batch in enumerate(val_dataloader):\n",
        "        with torch.no_grad():\n",
        "            img = batch[\"img\"].type(Tensor)\n",
        "            real_dose = batch[\"dose\"].type(Tensor)\n",
        "\n",
        "            generated_dose = generator(img)\n",
        "            discriminator_on_real_dose = discriminator(img, real_dose[:, None, :, :])\n",
        "            discriminator_on_generated_dose = discriminator(img, generated_dose)\n",
        "            \n",
        "            pos_sample_labels = torch.ones(size=(len(real_dose), 1), device=DEVICE)\n",
        "            neg_sample_labels = torch.zeros(size=(len(real_dose), 1), device=DEVICE)\n",
        "            pos_sample_preds = torch.nn.Sigmoid()(discriminator_on_real_dose)\n",
        "            neg_sample_preds = torch.nn.Sigmoid()(discriminator_on_generated_dose)\n",
        "            \n",
        "            pos_samples_loss = cross_entropy_loss(\n",
        "                input=discriminator_on_real_dose, target=pos_sample_labels\n",
        "            )\n",
        "            \n",
        "            neg_samples_loss = cross_entropy_loss(\n",
        "                input=discriminator_on_generated_dose, target=neg_sample_labels\n",
        "            )\n",
        "            \n",
        "            discriminator_loss = (pos_samples_loss + neg_samples_loss) / 2\n",
        "            \n",
        "            val_loss_d.append(discriminator_loss.item())\n",
        "            \n",
        "            d_acc = accuracy_fn(\n",
        "                torch.cat((pos_sample_preds, neg_sample_preds), dim=-1),\n",
        "                torch.cat((pos_sample_labels, neg_sample_labels), dim=-1).type(torch.int)\n",
        "            ).item()\n",
        "            val_acc_d.append(d_acc)\n",
        "            \n",
        "            generator_l1_loss = l1_criterion(\n",
        "                input=generated_dose[:, 0, :, :],\n",
        "                target=real_dose\n",
        "            )\n",
        "            generator_adversarial_loss = cross_entropy_loss(\n",
        "                input=discriminator_on_generated_dose,\n",
        "                target=torch.ones(size=(len(real_dose), 1), device=DEVICE)\n",
        "            )\n",
        "            \n",
        "            generator_loss = ALPHA * generator_adversarial_loss + (1 - ALPHA) * generator_l1_loss\n",
        "            \n",
        "            val_l1_loss_g.append(generator_l1_loss.item())\n",
        "            val_adversarial_loss_g.append(generator_adversarial_loss.item())\n",
        "\n",
        "    logger.add_scalar(tag=f\"val/discrimintor_loss\", scalar_value=np.mean(val_loss_d), global_step=epoch)\n",
        "    logger.add_scalar(tag=f\"val/discrimintor_accuracy\", scalar_value=np.mean(val_acc_d), global_step=epoch)\n",
        "    logger.add_scalar(tag=f\"val/generator_l1_loss\", scalar_value=np.mean(val_l1_loss_g), global_step=epoch)\n",
        "    logger.add_scalar(tag=f\"val/generator_adversarial_loss\", scalar_value=np.mean(val_adversarial_loss_g), global_step=epoch)\n",
        "    \n",
        "    progress_bar.set_description(f\"EPOCH [{epoch + 1}/{N_EPOCHS}]\\nDiscriminator: Val Loss: {np.mean(val_loss_d):.2f}\\nGenerator: Val Loss: {ALPHA * np.mean(val_l1_loss_g) + (1 - ALPHA) * np.mean(val_adversarial_loss_g):.2f}\")\n",
        "    \n",
        "    torch.save(generator.state_dict(), EXP_DIR/\"generator.pt\")\n",
        "    torch.save(discriminator.state_dict(), EXP_DIR/\"discriminator.pt\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# EVALUATE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UyWcr0GDpvZ9"
      },
      "outputs": [],
      "source": [
        "def evaluate_generator(generator):\n",
        "    \"\"\"Evaluate a generator.\n",
        "\n",
        "    Args:\n",
        "        generator: (GeneratorUNet) neural network generating T2-w images\n",
        "\n",
        "    \"\"\"\n",
        "    res_train, res_test = [], []\n",
        "\n",
        "    cuda = True if torch.cuda.is_available() else False\n",
        "    Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for i, batch in enumerate(train_dataloader):\n",
        "\n",
        "            # Inputs T1-w and T2-w\n",
        "            real_img = batch[\"img\"].type(Tensor)\n",
        "            real_dose = batch[\"dose\"].type(Tensor)\n",
        "            real_possible_dose_mask = batch[\"possible_dose_mask\"].type(Tensor)\n",
        "            fake_dose = generator(real_img)\n",
        "            fake_dose = (real_possible_dose_mask*fake_dose[:, 0, :,:])\n",
        "\n",
        "            mae = mean_absolute_error(real_dose, fake_dose).item()\n",
        "            psnr = peak_signal_to_noise_ratio(real_dose, fake_dose).item()\n",
        "            ssim = structural_similarity_index(real_dose, fake_dose).item()\n",
        "\n",
        "            res_train.append([mae, psnr, ssim])\n",
        "\n",
        "        for i, batch in enumerate(val_dataloader):\n",
        "\n",
        "            # Inputs T1-w and T2-w\n",
        "            real_img = batch[\"img\"].type(Tensor)\n",
        "            real_dose = batch[\"dose\"].type(Tensor)\n",
        "            real_possible_dose_mask = batch[\"possible_dose_mask\"].type(Tensor)\n",
        "            fake_dose = generator(real_img)\n",
        "            fake_dose = (real_possible_dose_mask*fake_dose[:, 0, :,:])\n",
        "\n",
        "            mae = mean_absolute_error(real_dose, fake_dose).item()\n",
        "            psnr = peak_signal_to_noise_ratio(real_dose, fake_dose).item()\n",
        "            ssim = structural_similarity_index(real_dose, fake_dose).item()\n",
        "\n",
        "            res_test.append([mae, psnr, ssim])\n",
        "\n",
        "        df = pd.DataFrame([\n",
        "            pd.DataFrame(res_train, columns=['MAE', 'PSNR', 'SSIM']).mean().squeeze(),\n",
        "            pd.DataFrame(res_test, columns=['MAE', 'PSNR', 'SSIM']).mean().squeeze()\n",
        "        ], index=['Training set', 'Test set']).T\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GYlR6_iAqH5g"
      },
      "outputs": [],
      "source": [
        "df = evaluate_generator(generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "RHogVywxwplr",
        "outputId": "d56d6b22-f849-4b91-e225-db98ac550434"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "jupytext": {
      "cell_metadata_json": true,
      "main_language": "python"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
